{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c989f319-509e-4160-82fe-49b15be5f57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from lightgbm import LGBMRegressor\n",
    "import joblib\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92bfa126-7ce6-4bb4-844f-cc181eca5008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FINAL ENHANCED TRAINING - TARGET ENCODING + ADVANCED FEATURES\n",
      "============================================================\n",
      "\n",
      "Original shape: (266733, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"FINAL ENHANCED TRAINING - TARGET ENCODING + ADVANCED FEATURES\")\n",
    "print(\"=\"*60)\n",
    "# Load data\n",
    "df = pd.read_csv(\"../backend/data/preprocessed_data.csv\")\n",
    "print(f\"\\nOriginal shape: {df.shape}\")\n",
    "# Remove Year\n",
    "if 'Year' in df.columns:\n",
    "    df = df.drop('Year', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85cbe638-9c16-41af-b3cd-83be838a5cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¯ Creating target-encoded features...\n",
      "âœ… Created target-encoded features\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# TARGET ENCODING (CRITICAL FOR RARE COMBINATIONS!)\n",
    "# ========================================\n",
    "print(\"\\nðŸŽ¯ Creating target-encoded features...\")\n",
    "# Split first to avoid data leakage\n",
    "X_temp = df.drop('Yield', axis=1)\n",
    "y_temp = df['Yield']\n",
    "X_train_temp, X_test_temp, y_train_temp, y_test_temp = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.2, random_state=42\n",
    ")\n",
    "# Create target encoding on training data only\n",
    "train_df = X_train_temp.copy()\n",
    "train_df['Yield'] = y_train_temp\n",
    "# Target encode: mean yield per category\n",
    "df['Crop_Mean_Yield'] = df['Crop'].map(train_df.groupby('Crop')['Yield'].mean())\n",
    "df['State_Mean_Yield'] = df['State'].map(train_df.groupby('State')['Yield'].mean())\n",
    "df['Season_Mean_Yield'] = df['Season'].map(train_df.groupby('Season')['Yield'].mean())\n",
    "# Combination encodings\n",
    "df['Crop_State_Mean'] = df.apply(lambda x: f\"{x['Crop']}_{x['State']}\", axis=1)\n",
    "crop_state_means = train_df.groupby(['Crop', 'State'])['Yield'].mean().to_dict()\n",
    "df['Crop_State_Mean_Yield'] = df.apply(lambda x: crop_state_means.get((x['Crop'], x['State']), df['Yield'].mean()), axis=1)\n",
    "df['Crop_Season_Mean'] = df.apply(lambda x: f\"{x['Crop']}_{x['Season']}\", axis=1)\n",
    "crop_season_means = train_df.groupby(['Crop', 'Season'])['Yield'].mean().to_dict()\n",
    "df['Crop_Season_Mean_Yield'] = df.apply(lambda x: crop_season_means.get((x['Crop'], x['Season']), df['Yield'].mean()), axis=1)\n",
    "# Save these mappings for inference\n",
    "target_encodings = {\n",
    "    'crop_means': train_df.groupby('Crop')['Yield'].mean().to_dict(),\n",
    "    'state_means': train_df.groupby('State')['Yield'].mean().to_dict(),\n",
    "    'season_means': train_df.groupby('Season')['Yield'].mean().to_dict(),\n",
    "    'crop_state_means': crop_state_means,\n",
    "    'crop_season_means': crop_season_means,\n",
    "    'global_mean': train_df['Yield'].mean()\n",
    "}\n",
    "print(f\"âœ… Created target-encoded features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddc0b7af-dab5-4cc6-aec1-eda4a01d4362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”§ Creating advanced features...\n",
      "âœ… Created 25 total features\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# ADVANCED FEATURE ENGINEERING\n",
    "# ========================================\n",
    "print(\"\\nðŸ”§ Creating advanced features...\")\n",
    "# Interaction features\n",
    "df['Rainfall_per_Fertilizer'] = df['Annual_Rainfall'] / (df['Fertilizer'] + 1)\n",
    "df['Fertilizer_Pesticide_Ratio'] = df['Fertilizer'] / (df['Pesticide'] + 0.01)\n",
    "df['Total_Input'] = df['Fertilizer'] + df['Pesticide']\n",
    "df['Rainfall_Fertilizer_Product'] = df['Annual_Rainfall'] * df['Fertilizer']\n",
    "# Polynomial features\n",
    "df['Rainfall_Squared'] = df['Annual_Rainfall'] ** 2\n",
    "df['Fertilizer_Squared'] = df['Fertilizer'] ** 2\n",
    "df['Pesticide_Squared'] = df['Pesticide'] ** 2\n",
    "# Log transformations\n",
    "df['Log_Rainfall'] = np.log1p(df['Annual_Rainfall'])\n",
    "df['Log_Fertilizer'] = np.log1p(df['Fertilizer'])\n",
    "df['Log_Pesticide'] = np.log1p(df['Pesticide'])\n",
    "# Binning (helps model learn thresholds)\n",
    "df['Rainfall_Bin'] = pd.cut(df['Annual_Rainfall'], bins=10, labels=False)\n",
    "df['Fertilizer_Bin'] = pd.cut(df['Fertilizer'], bins=10, labels=False)\n",
    "print(f\"âœ… Created {len(df.columns) - 1} total features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce0f610e-db97-42d6-a6f8-4f3c4ad08497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Encoding\n",
    "# ========================================\n",
    "df_encoded = df.copy()\n",
    "encoders = {}\n",
    "categorical_cols = ['State', 'Crop', 'Season']\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_encoded[col] = le.fit_transform(df_encoded[col])\n",
    "    encoders[col] = le\n",
    "# Drop temporary columns\n",
    "df_encoded = df_encoded.drop(['Crop_State_Mean', 'Crop_Season_Mean'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75663dee-c8d7-4aca-b7ba-1c223efa1afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "X = df_encoded.drop('Yield', axis=1)\n",
    "y = df_encoded['Yield']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfd82a5f-6308-4b9d-9e03-d82bc4d7cdeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train size: 213386, Test size: 53347\n"
     ]
    }
   ],
   "source": [
    "# Convert categorical columns to category dtype\n",
    "X_train_lgb = X_train.copy()\n",
    "X_test_lgb = X_test.copy()\n",
    "for col in categorical_cols:\n",
    "    if col in X_train_lgb.columns:\n",
    "        X_train_lgb[col] = X_train_lgb[col].astype('category')\n",
    "        X_test_lgb[col] = X_test_lgb[col].astype('category')\n",
    "print(f\"\\nTrain size: {len(X_train)}, Test size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de000568-3922-44b3-814c-48880a0ab5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-30 13:45:24,554] A new study created in memory with name: no-name-0ef00e33-eacb-492a-97ba-018bb47fedfa\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Running Optuna (40 trials for better optimization)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61fe2f10dcdc4f7f9f631e3ff6c6e7e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-30 13:46:14,315] Trial 0 finished with value: 0.8664352172781292 and parameters: {'n_estimators': 1062, 'learning_rate': 0.0862735828664018, 'num_leaves': 195, 'max_depth': 17, 'min_child_samples': 19, 'subsample': 0.662397808134481, 'colsample_bytree': 0.6232334448672797, 'reg_alpha': 8.661761457749352, 'reg_lambda': 6.011150117432088, 'min_split_gain': 0.7080725777960455}. Best is trial 0 with value: 0.8664352172781292.\n",
      "[I 2025-11-30 13:46:37,558] Trial 1 finished with value: 0.8665255386104805 and parameters: {'n_estimators': 530, 'learning_rate': 0.09138013915892866, 'num_leaves': 218, 'max_depth': 9, 'min_child_samples': 22, 'subsample': 0.6733618039413735, 'colsample_bytree': 0.7216968971838151, 'reg_alpha': 5.247564316322379, 'reg_lambda': 4.319450186421157, 'min_split_gain': 0.2912291401980419}. Best is trial 1 with value: 0.8665255386104805.\n",
      "[I 2025-11-30 13:47:42,424] Trial 2 finished with value: 0.8682729335970523 and parameters: {'n_estimators': 1418, 'learning_rate': 0.007593739613361234, 'num_leaves': 96, 'max_depth': 12, 'min_child_samples': 48, 'subsample': 0.9140703845572055, 'colsample_bytree': 0.6798695128633439, 'reg_alpha': 5.142344384136116, 'reg_lambda': 5.924145688620425, 'min_split_gain': 0.046450412719997725}. Best is trial 2 with value: 0.8682729335970523.\n",
      "[I 2025-11-30 13:48:31,775] Trial 3 finished with value: 0.8702622562110133 and parameters: {'n_estimators': 1411, 'learning_rate': 0.008333491643033208, 'num_leaves': 45, 'max_depth': 24, 'min_child_samples': 97, 'subsample': 0.9233589392465844, 'colsample_bytree': 0.7218455076693483, 'reg_alpha': 0.9767211400638387, 'reg_lambda': 6.842330265121569, 'min_split_gain': 0.4401524937396013}. Best is trial 3 with value: 0.8702622562110133.\n",
      "[I 2025-11-30 13:48:48,947] Trial 4 finished with value: 0.8670187947536586 and parameters: {'n_estimators': 683, 'learning_rate': 0.022039920190846215, 'num_leaves': 38, 'max_depth': 24, 'min_child_samples': 29, 'subsample': 0.8650089137415928, 'colsample_bytree': 0.7246844304357644, 'reg_alpha': 5.200680211778108, 'reg_lambda': 5.4671027934327965, 'min_split_gain': 0.18485445552552704}. Best is trial 3 with value: 0.8702622562110133.\n",
      "[I 2025-11-30 13:51:12,255] Trial 5 finished with value: 0.8665781615180019 and parameters: {'n_estimators': 1955, 'learning_rate': 0.050984839695857445, 'num_leaves': 242, 'max_depth': 23, 'min_child_samples': 62, 'subsample': 0.9687496940092467, 'colsample_bytree': 0.6353970008207678, 'reg_alpha': 1.959828624191452, 'reg_lambda': 0.45227288910538066, 'min_split_gain': 0.32533033076326434}. Best is trial 3 with value: 0.8702622562110133.\n",
      "[I 2025-11-30 13:52:26,184] Trial 6 finished with value: 0.8671329960238415 and parameters: {'n_estimators': 1083, 'learning_rate': 0.01127205849868025, 'num_leaves': 217, 'max_depth': 12, 'min_child_samples': 31, 'subsample': 0.8170784332632994, 'colsample_bytree': 0.6563696899899051, 'reg_alpha': 8.021969807540398, 'reg_lambda': 0.7455064367977082, 'min_split_gain': 0.9868869366005173}. Best is trial 3 with value: 0.8702622562110133.\n",
      "[I 2025-11-30 13:53:17,283] Trial 7 finished with value: 0.8684109447091023 and parameters: {'n_estimators': 1659, 'learning_rate': 0.009067865433891705, 'num_leaves': 32, 'max_depth': 22, 'min_child_samples': 72, 'subsample': 0.8916028672163949, 'colsample_bytree': 0.9085081386743783, 'reg_alpha': 0.7404465173409036, 'reg_lambda': 3.5846572854427263, 'min_split_gain': 0.11586905952512971}. Best is trial 3 with value: 0.8702622562110133.\n",
      "[I 2025-11-30 13:54:05,961] Trial 8 finished with value: 0.8669347112922855 and parameters: {'n_estimators': 1795, 'learning_rate': 0.03235188302117385, 'num_leaves': 105, 'max_depth': 6, 'min_child_samples': 34, 'subsample': 0.7300733288106989, 'colsample_bytree': 0.8918424713352255, 'reg_alpha': 6.3755747135521315, 'reg_lambda': 8.872127425763265, 'min_split_gain': 0.4722149251619493}. Best is trial 3 with value: 0.8702622562110133.\n",
      "[I 2025-11-30 13:54:53,527] Trial 9 finished with value: 0.8674901179124614 and parameters: {'n_estimators': 679, 'learning_rate': 0.042356773126632795, 'num_leaves': 202, 'max_depth': 16, 'min_child_samples': 79, 'subsample': 0.7975182385457563, 'colsample_bytree': 0.8090931317527976, 'reg_alpha': 4.275410183585496, 'reg_lambda': 0.2541912674409519, 'min_split_gain': 0.10789142699330445}. Best is trial 3 with value: 0.8702622562110133.\n",
      "[I 2025-11-30 13:56:18,071] Trial 10 finished with value: 0.8718245850825017 and parameters: {'n_estimators': 1379, 'learning_rate': 0.005090641565719821, 'num_leaves': 147, 'max_depth': 19, 'min_child_samples': 99, 'subsample': 0.9630659181130071, 'colsample_bytree': 0.9839082983781678, 'reg_alpha': 2.7628601955555183, 'reg_lambda': 9.506149249776017, 'min_split_gain': 0.6437127366238236}. Best is trial 10 with value: 0.8718245850825017.\n",
      "[I 2025-11-30 13:57:48,686] Trial 11 finished with value: 0.8716434116826217 and parameters: {'n_estimators': 1444, 'learning_rate': 0.005139582621397722, 'num_leaves': 147, 'max_depth': 19, 'min_child_samples': 100, 'subsample': 0.9842382368815334, 'colsample_bytree': 0.996380128364447, 'reg_alpha': 2.1785358383633726, 'reg_lambda': 9.60033306888927, 'min_split_gain': 0.6651803039734121}. Best is trial 10 with value: 0.8718245850825017.\n",
      "[I 2025-11-30 13:58:45,014] Trial 12 finished with value: 0.8718019222036659 and parameters: {'n_estimators': 1312, 'learning_rate': 0.005194054617562398, 'num_leaves': 148, 'max_depth': 19, 'min_child_samples': 100, 'subsample': 0.9977163178526613, 'colsample_bytree': 0.9968147883372204, 'reg_alpha': 3.4279928826631645, 'reg_lambda': 9.898005744015766, 'min_split_gain': 0.717479526485661}. Best is trial 10 with value: 0.8718245850825017.\n",
      "[I 2025-11-30 13:59:34,432] Trial 13 finished with value: 0.8714830346564959 and parameters: {'n_estimators': 1141, 'learning_rate': 0.005068141814696057, 'num_leaves': 153, 'max_depth': 20, 'min_child_samples': 86, 'subsample': 0.9995784073374041, 'colsample_bytree': 0.9948046416005474, 'reg_alpha': 3.03446300888558, 'reg_lambda': 8.080660344471642, 'min_split_gain': 0.7380983421262326}. Best is trial 10 with value: 0.8718245850825017.\n",
      "[I 2025-11-30 14:00:22,932] Trial 14 finished with value: 0.8690793830351676 and parameters: {'n_estimators': 932, 'learning_rate': 0.016687771290136575, 'num_leaves': 171, 'max_depth': 19, 'min_child_samples': 86, 'subsample': 0.9429564520037396, 'colsample_bytree': 0.9199590390396316, 'reg_alpha': 3.5790059406286208, 'reg_lambda': 7.639748102912022, 'min_split_gain': 0.9065864123052301}. Best is trial 10 with value: 0.8718245850825017.\n",
      "[I 2025-11-30 14:01:22,672] Trial 15 finished with value: 0.8663619144132338 and parameters: {'n_estimators': 1606, 'learning_rate': 0.013022603089321984, 'num_leaves': 104, 'max_depth': 13, 'min_child_samples': 5, 'subsample': 0.8557873865083511, 'colsample_bytree': 0.9481404729080235, 'reg_alpha': 6.7327179076466, 'reg_lambda': 9.560354786783218, 'min_split_gain': 0.5926353644208063}. Best is trial 10 with value: 0.8718245850825017.\n",
      "[I 2025-11-30 14:02:10,477] Trial 16 finished with value: 0.8697572853447213 and parameters: {'n_estimators': 1291, 'learning_rate': 0.006702438640189255, 'num_leaves': 117, 'max_depth': 15, 'min_child_samples': 63, 'subsample': 0.6094781646023328, 'colsample_bytree': 0.8426668125649943, 'reg_alpha': 2.702049374135272, 'reg_lambda': 9.990877940427831, 'min_split_gain': 0.8139937055778315}. Best is trial 10 with value: 0.8718245850825017.\n",
      "[I 2025-11-30 14:02:42,776] Trial 17 finished with value: 0.8698463071663289 and parameters: {'n_estimators': 896, 'learning_rate': 0.01615167895371149, 'num_leaves': 76, 'max_depth': 21, 'min_child_samples': 90, 'subsample': 0.7730982444721965, 'colsample_bytree': 0.9575567008262806, 'reg_alpha': 1.4153299935549413, 'reg_lambda': 3.1378380000280544, 'min_split_gain': 0.5770477796572194}. Best is trial 10 with value: 0.8718245850825017.\n",
      "[I 2025-11-30 14:03:38,646] Trial 18 finished with value: 0.8703650947986127 and parameters: {'n_estimators': 1288, 'learning_rate': 0.006204686551604291, 'num_leaves': 176, 'max_depth': 17, 'min_child_samples': 73, 'subsample': 0.9576552310275883, 'colsample_bytree': 0.8413830212925287, 'reg_alpha': 3.8245155754082045, 'reg_lambda': 8.036285922307083, 'min_split_gain': 0.824708442200609}. Best is trial 10 with value: 0.8718245850825017.\n",
      "[I 2025-11-30 14:04:43,802] Trial 19 finished with value: 0.8673322084058185 and parameters: {'n_estimators': 1630, 'learning_rate': 0.010691603807201295, 'num_leaves': 133, 'max_depth': 14, 'min_child_samples': 46, 'subsample': 0.8793596230812959, 'colsample_bytree': 0.8792386560021603, 'reg_alpha': 0.11620961627553239, 'reg_lambda': 1.90286598289285, 'min_split_gain': 0.5720615865449301}. Best is trial 10 with value: 0.8718245850825017.\n",
      "[I 2025-11-30 14:05:59,563] Trial 20 finished with value: 0.868432911802055 and parameters: {'n_estimators': 1527, 'learning_rate': 0.020913123185093942, 'num_leaves': 129, 'max_depth': 25, 'min_child_samples': 100, 'subsample': 0.8265847329840579, 'colsample_bytree': 0.9480642973080262, 'reg_alpha': 6.329707519600637, 'reg_lambda': 6.870861237875773, 'min_split_gain': 0.8341953390861175}. Best is trial 10 with value: 0.8718245850825017.\n",
      "[I 2025-11-30 14:07:05,978] Trial 21 finished with value: 0.8711169858033451 and parameters: {'n_estimators': 1431, 'learning_rate': 0.005698302141498024, 'num_leaves': 151, 'max_depth': 19, 'min_child_samples': 95, 'subsample': 0.9989879313923893, 'colsample_bytree': 0.9886918706800445, 'reg_alpha': 2.2764204517668456, 'reg_lambda': 9.011493027457238, 'min_split_gain': 0.6867232046141587}. Best is trial 10 with value: 0.8718245850825017.\n",
      "[I 2025-11-30 14:07:58,069] Trial 22 finished with value: 0.871391775617818 and parameters: {'n_estimators': 1217, 'learning_rate': 0.005065353936544118, 'num_leaves': 171, 'max_depth': 18, 'min_child_samples': 82, 'subsample': 0.96497685444517, 'colsample_bytree': 0.9964166390788595, 'reg_alpha': 9.994134940876853, 'reg_lambda': 8.899597294358168, 'min_split_gain': 0.6371682927081008}. Best is trial 10 with value: 0.8718245850825017.\n",
      "[I 2025-11-30 14:09:31,604] Trial 23 finished with value: 0.8701903468545508 and parameters: {'n_estimators': 1753, 'learning_rate': 0.007334200443986832, 'num_leaves': 147, 'max_depth': 21, 'min_child_samples': 100, 'subsample': 0.999652076223965, 'colsample_bytree': 0.9552074049627364, 'reg_alpha': 3.143577101586957, 'reg_lambda': 9.647128510317986, 'min_split_gain': 0.4022421286828864}. Best is trial 10 with value: 0.8718245850825017.\n",
      "[I 2025-11-30 14:10:19,653] Trial 24 finished with value: 0.8699319521076578 and parameters: {'n_estimators': 1335, 'learning_rate': 0.009216501453584772, 'num_leaves': 82, 'max_depth': 19, 'min_child_samples': 92, 'subsample': 0.9207421871415696, 'colsample_bytree': 0.970983948147751, 'reg_alpha': 4.338671834215321, 'reg_lambda': 7.309998564273489, 'min_split_gain': 0.7625658160608287}. Best is trial 10 with value: 0.8718245850825017.\n",
      "[I 2025-11-30 14:11:35,059] Trial 25 finished with value: 0.8699694547864473 and parameters: {'n_estimators': 1515, 'learning_rate': 0.006434147287680695, 'num_leaves': 164, 'max_depth': 16, 'min_child_samples': 76, 'subsample': 0.9631417618880532, 'colsample_bytree': 0.9245129662476347, 'reg_alpha': 1.5553691230533069, 'reg_lambda': 8.655147652236984, 'min_split_gain': 0.5393901601234998}. Best is trial 10 with value: 0.8718245850825017.\n",
      "[I 2025-11-30 14:12:25,654] Trial 26 finished with value: 0.8681554415684586 and parameters: {'n_estimators': 1174, 'learning_rate': 0.013235365650551827, 'num_leaves': 126, 'max_depth': 21, 'min_child_samples': 62, 'subsample': 0.9050801032194264, 'colsample_bytree': 0.8647572583631183, 'reg_alpha': 2.378026976456025, 'reg_lambda': 9.969351766655267, 'min_split_gain': 0.6514577998226955}. Best is trial 10 with value: 0.8718245850825017.\n",
      "[I 2025-11-30 14:13:04,946] Trial 27 finished with value: 0.8720202324366646 and parameters: {'n_estimators': 985, 'learning_rate': 0.0050960322019653545, 'num_leaves': 190, 'max_depth': 18, 'min_child_samples': 90, 'subsample': 0.9328194752017529, 'colsample_bytree': 0.7625759553737261, 'reg_alpha': 0.16825957271390024, 'reg_lambda': 8.311007005387273, 'min_split_gain': 0.9373906685350466}. Best is trial 27 with value: 0.8720202324366646.\n",
      "[I 2025-11-30 14:13:34,709] Trial 28 finished with value: 0.870817286973543 and parameters: {'n_estimators': 914, 'learning_rate': 0.009962882776665032, 'num_leaves': 186, 'max_depth': 10, 'min_child_samples': 90, 'subsample': 0.9400837420097774, 'colsample_bytree': 0.7862831516423896, 'reg_alpha': 0.17887695182030466, 'reg_lambda': 8.452443477951755, 'min_split_gain': 0.9950934825884539}. Best is trial 27 with value: 0.8720202324366646.\n",
      "[I 2025-11-30 14:14:20,231] Trial 29 finished with value: 0.8672675007887737 and parameters: {'n_estimators': 1003, 'learning_rate': 0.030094200464123574, 'num_leaves': 200, 'max_depth': 16, 'min_child_samples': 69, 'subsample': 0.7530637371908914, 'colsample_bytree': 0.7828263087076119, 'reg_alpha': 1.0582301350288241, 'reg_lambda': 6.520121901425519, 'min_split_gain': 0.9038709684812356}. Best is trial 27 with value: 0.8720202324366646.\n",
      "[I 2025-11-30 14:14:54,336] Trial 30 finished with value: 0.8672865738899935 and parameters: {'n_estimators': 761, 'learning_rate': 0.061739213420533394, 'num_leaves': 225, 'max_depth': 17, 'min_child_samples': 86, 'subsample': 0.8481830511866643, 'colsample_bytree': 0.755019587405858, 'reg_alpha': 4.549260602696678, 'reg_lambda': 7.55132656756861, 'min_split_gain': 0.9015637100930598}. Best is trial 27 with value: 0.8720202324366646.\n",
      "[I 2025-11-30 14:15:41,967] Trial 31 finished with value: 0.8720015224138384 and parameters: {'n_estimators': 1113, 'learning_rate': 0.005174259706038979, 'num_leaves': 189, 'max_depth': 18, 'min_child_samples': 100, 'subsample': 0.9767542265662768, 'colsample_bytree': 0.9734465393242449, 'reg_alpha': 1.9001467987906069, 'reg_lambda': 9.252785995205196, 'min_split_gain': 0.7461100731358977}. Best is trial 27 with value: 0.8720202324366646.\n",
      "[I 2025-11-30 14:16:30,537] Trial 32 finished with value: 0.8714271889123149 and parameters: {'n_estimators': 1072, 'learning_rate': 0.006368403179376831, 'num_leaves': 186, 'max_depth': 18, 'min_child_samples': 94, 'subsample': 0.9388891680437451, 'colsample_bytree': 0.9299257144677591, 'reg_alpha': 3.363408554279574, 'reg_lambda': 9.23229314587567, 'min_split_gain': 0.7674152324822947}. Best is trial 27 with value: 0.8720202324366646.\n",
      "[I 2025-11-30 14:17:25,987] Trial 33 finished with value: 0.8708128449714316 and parameters: {'n_estimators': 1003, 'learning_rate': 0.007478422091855437, 'num_leaves': 248, 'max_depth': 20, 'min_child_samples': 82, 'subsample': 0.9803352379816822, 'colsample_bytree': 0.9713293520608642, 'reg_alpha': 1.729646839689214, 'reg_lambda': 8.136065982848185, 'min_split_gain': 0.7324757645467597}. Best is trial 27 with value: 0.8720202324366646.\n",
      "[I 2025-11-30 14:18:01,868] Trial 34 finished with value: 0.8712899214827521 and parameters: {'n_estimators': 834, 'learning_rate': 0.008089123697580922, 'num_leaves': 217, 'max_depth': 15, 'min_child_samples': 92, 'subsample': 0.9423043626883857, 'colsample_bytree': 0.6881868190070022, 'reg_alpha': 0.6422051537900102, 'reg_lambda': 4.849709621354269, 'min_split_gain': 0.8555339563165055}. Best is trial 27 with value: 0.8720202324366646.\n",
      "[I 2025-11-30 14:19:00,240] Trial 35 finished with value: 0.8713980946584083 and parameters: {'n_estimators': 1348, 'learning_rate': 0.005735129622058611, 'num_leaves': 186, 'max_depth': 18, 'min_child_samples': 96, 'subsample': 0.9058532990786837, 'colsample_bytree': 0.7518029645641762, 'reg_alpha': 2.7252344655378065, 'reg_lambda': 9.25665287036494, 'min_split_gain': 0.5088507441851737}. Best is trial 27 with value: 0.8720202324366646.\n",
      "[I 2025-11-30 14:19:17,635] Trial 36 finished with value: 0.8719513562308968 and parameters: {'n_estimators': 514, 'learning_rate': 0.0075794240528840665, 'num_leaves': 159, 'max_depth': 23, 'min_child_samples': 89, 'subsample': 0.9291415213996559, 'colsample_bytree': 0.8355560148961885, 'reg_alpha': 5.688176998681454, 'reg_lambda': 5.9249918035886475, 'min_split_gain': 0.9535584434949083}. Best is trial 27 with value: 0.8720202324366646.\n",
      "[I 2025-11-30 14:19:37,273] Trial 37 finished with value: 0.8708547170259173 and parameters: {'n_estimators': 526, 'learning_rate': 0.0075342136319106485, 'num_leaves': 232, 'max_depth': 23, 'min_child_samples': 53, 'subsample': 0.8835703839930775, 'colsample_bytree': 0.6005800047171014, 'reg_alpha': 5.297877240900142, 'reg_lambda': 5.744230067327038, 'min_split_gain': 0.947671352178977}. Best is trial 27 with value: 0.8720202324366646.\n",
      "[I 2025-11-30 14:20:08,559] Trial 38 finished with value: 0.870753783329433 and parameters: {'n_estimators': 636, 'learning_rate': 0.012083196308495737, 'num_leaves': 204, 'max_depth': 25, 'min_child_samples': 86, 'subsample': 0.9096638555255708, 'colsample_bytree': 0.816798966242103, 'reg_alpha': 5.630259235390823, 'reg_lambda': 6.448104246799218, 'min_split_gain': 0.9427570875135716}. Best is trial 27 with value: 0.8720202324366646.\n",
      "[I 2025-11-30 14:20:37,556] Trial 39 finished with value: 0.8668913457770788 and parameters: {'n_estimators': 616, 'learning_rate': 0.07655681778391892, 'num_leaves': 159, 'max_depth': 22, 'min_child_samples': 80, 'subsample': 0.9295915899518554, 'colsample_bytree': 0.7065058409554322, 'reg_alpha': 7.601768164177224, 'reg_lambda': 5.0711512675749555, 'min_split_gain': 0.873026967039402}. Best is trial 27 with value: 0.8720202324366646.\n",
      "\n",
      "âœ… Best params found! Best CV RÂ²: 0.8720\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# Hyperparameter Tuning with MORE trials\n",
    "# ========================================\n",
    "print(\"\\nðŸš€ Running Optuna (40 trials for better optimization)...\")\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 2000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 31, 255),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 25),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0),\n",
    "        'min_split_gain': trial.suggest_float('min_split_gain', 0.0, 1.0),\n",
    "        'random_state': 42,\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    model = LGBMRegressor(**params)\n",
    "    \n",
    "    # 5-fold CV for better estimate\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X_train_lgb):\n",
    "        X_tr, X_val = X_train_lgb.iloc[train_idx], X_train_lgb.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        model.fit(X_tr, y_tr, categorical_feature='auto')\n",
    "        pred = model.predict(X_val)\n",
    "        scores.append(r2_score(y_val, pred))\n",
    "    \n",
    "    return np.mean(scores)\n",
    "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=40, show_progress_bar=True)  # Changed from 100 to 40\n",
    "print(f\"\\nâœ… Best params found! Best CV RÂ²: {study.best_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da1a62b3-daac-4227-ab09-38b36de3d6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ† Final Model Performance:\n",
      "   RÂ²:   0.8823\n",
      "   MAE:  22.4116\n",
      "   RMSE: 330.5909\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# Train final model\n",
    "# ========================================\n",
    "best_params = study.best_params\n",
    "best_lgb = LGBMRegressor(**best_params)\n",
    "best_lgb.fit(X_train_lgb, y_train, categorical_feature='auto')\n",
    "# Evaluate\n",
    "lgb_pred = best_lgb.predict(X_test_lgb)\n",
    "lgb_r2 = r2_score(y_test, lgb_pred)\n",
    "lgb_mae = mean_absolute_error(y_test, lgb_pred)\n",
    "lgb_rmse = np.sqrt(mean_squared_error(y_test, lgb_pred))\n",
    "print(f\"\\nðŸ† Final Model Performance:\")\n",
    "print(f\"   RÂ²:   {lgb_r2:.4f}\")\n",
    "print(f\"   MAE:  {lgb_mae:.4f}\")\n",
    "print(f\"   RMSE: {lgb_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e27ba48d-767d-4be5-a231-d3443f6aafba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING ON YOUR EXAMPLE\n",
      "============================================================\n",
      "\n",
      "Your test case:\n",
      "  Predicted: 1.067837\n",
      "  Actual:    0.468989\n",
      "  Error:     0.598848 (127.69%)\n",
      "\n",
      "âš ï¸  Still needs improvement\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# Test on your example\n",
    "# ========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TESTING ON YOUR EXAMPLE\")\n",
    "print(\"=\"*60)\n",
    "test_case = pd.DataFrame([{\n",
    "    'Crop': 'arhar/tur',\n",
    "    'State': 'andhra pradesh',\n",
    "    'Season': 'kharif',\n",
    "    'Annual_Rainfall': 928.4,\n",
    "    'Fertilizer': 102.13,\n",
    "    'Pesticide': 0.26\n",
    "}])\n",
    "# Apply target encoding\n",
    "test_case['Crop_Mean_Yield'] = target_encodings['crop_means'].get(test_case['Crop'].iloc[0], target_encodings['global_mean'])\n",
    "test_case['State_Mean_Yield'] = target_encodings['state_means'].get(test_case['State'].iloc[0], target_encodings['global_mean'])\n",
    "test_case['Season_Mean_Yield'] = target_encodings['season_means'].get(test_case['Season'].iloc[0], target_encodings['global_mean'])\n",
    "test_case['Crop_State_Mean_Yield'] = target_encodings['crop_state_means'].get(\n",
    "    (test_case['Crop'].iloc[0], test_case['State'].iloc[0]), target_encodings['global_mean']\n",
    ")\n",
    "test_case['Crop_Season_Mean_Yield'] = target_encodings['crop_season_means'].get(\n",
    "    (test_case['Crop'].iloc[0], test_case['Season'].iloc[0]), target_encodings['global_mean']\n",
    ")\n",
    "# Apply feature engineering\n",
    "test_case['Rainfall_per_Fertilizer'] = test_case['Annual_Rainfall'] / (test_case['Fertilizer'] + 1)\n",
    "test_case['Fertilizer_Pesticide_Ratio'] = test_case['Fertilizer'] / (test_case['Pesticide'] + 0.01)\n",
    "test_case['Total_Input'] = test_case['Fertilizer'] + test_case['Pesticide']\n",
    "test_case['Rainfall_Fertilizer_Product'] = test_case['Annual_Rainfall'] * test_case['Fertilizer']\n",
    "test_case['Rainfall_Squared'] = test_case['Annual_Rainfall'] ** 2\n",
    "test_case['Fertilizer_Squared'] = test_case['Fertilizer'] ** 2\n",
    "test_case['Pesticide_Squared'] = test_case['Pesticide'] ** 2\n",
    "test_case['Log_Rainfall'] = np.log1p(test_case['Annual_Rainfall'])\n",
    "test_case['Log_Fertilizer'] = np.log1p(test_case['Fertilizer'])\n",
    "test_case['Log_Pesticide'] = np.log1p(test_case['Pesticide'])\n",
    "test_case['Rainfall_Bin'] = pd.cut(test_case['Annual_Rainfall'], bins=10, labels=False).astype(float)\n",
    "test_case['Fertilizer_Bin'] = pd.cut(test_case['Fertilizer'], bins=10, labels=False).astype(float)\n",
    "# Encode\n",
    "for col in categorical_cols:\n",
    "    if col in test_case.columns:\n",
    "        test_case[col] = encoders[col].transform(test_case[col])\n",
    "        test_case[col] = test_case[col].astype('category')\n",
    "# Reorder\n",
    "feature_order = X_train.columns.tolist()\n",
    "test_case = test_case[feature_order]\n",
    "# Predict\n",
    "pred = best_lgb.predict(test_case)[0]\n",
    "actual = 0.468989\n",
    "print(f\"\\nYour test case:\")\n",
    "print(f\"  Predicted: {pred:.6f}\")\n",
    "print(f\"  Actual:    {actual:.6f}\")\n",
    "print(f\"  Error:     {abs(pred - actual):.6f} ({abs(pred - actual)/actual*100:.2f}%)\")\n",
    "if abs(pred - actual) / actual < 0.2:\n",
    "    print(\"\\nâœ… EXCELLENT! Error < 20%\")\n",
    "elif abs(pred - actual) / actual < 0.5:\n",
    "    print(\"\\nâœ… GOOD! Error < 50%\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  Still needs improvement\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b76ef5-2f33-4a85-85d3-9bc311ff1ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40cfd022-af3c-4cf2-9deb-2acbb4c0c872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12411 good predictions\n",
      "\n",
      "============================================================\n",
      "GOOD DEMO EXAMPLE:\n",
      "============================================================\n",
      "State                              27.000000\n",
      "Crop                               49.000000\n",
      "Season                              1.000000\n",
      "Annual_Rainfall                   792.800000\n",
      "Fertilizer                        162.200000\n",
      "Pesticide                           0.350000\n",
      "Crop_Mean_Yield                     9.828521\n",
      "State_Mean_Yield                    5.943708\n",
      "Season_Mean_Yield                   2.610148\n",
      "Crop_State_Mean_Yield              12.440627\n",
      "Crop_Season_Mean_Yield             11.232837\n",
      "Rainfall_per_Fertilizer             4.857843\n",
      "Fertilizer_Pesticide_Ratio        450.555556\n",
      "Total_Input                       162.550000\n",
      "Rainfall_Fertilizer_Product    128592.160000\n",
      "Rainfall_Squared               628531.840000\n",
      "Fertilizer_Squared              26308.840000\n",
      "Pesticide_Squared                   0.122500\n",
      "Log_Rainfall                        6.676832\n",
      "Log_Fertilizer                      5.094976\n",
      "Log_Pesticide                       0.300105\n",
      "Rainfall_Bin                        0.000000\n",
      "Fertilizer_Bin                      6.000000\n",
      "Name: 245323, dtype: float64\n",
      "\n",
      "Actual: 11.5000\n",
      "Predicted: 12.5059\n",
      "Error: 8.75%\n",
      "\n",
      "============================================================\n",
      "ORIGINAL VALUES (before encoding):\n",
      "============================================================\n",
      "\n",
      "Top 5 best predictions:\n",
      "\n",
      "1. Actual: 58.8992, Predicted: 58.8986, Error: 0.00%\n",
      "\n",
      "2. Actual: 4.7531, Predicted: 4.7533, Error: 0.00%\n",
      "\n",
      "3. Actual: 45.2000, Predicted: 45.2023, Error: 0.01%\n",
      "\n",
      "4. Actual: 1.6897, Predicted: 1.6897, Error: 0.01%\n",
      "\n",
      "5. Actual: 40.1866, Predicted: 40.1839, Error: 0.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tejas\\AppData\\Local\\Temp\\ipykernel_17972\\825893236.py:2: RuntimeWarning: divide by zero encountered in divide\n",
      "  errors = abs(y_test.values - lgb_pred) / y_test.values * 100\n"
     ]
    }
   ],
   "source": [
    "# Find test cases with low error\n",
    "errors = abs(y_test.values - lgb_pred) / y_test.values * 100\n",
    "good_mask = errors < 20\n",
    "good_positions = np.where(good_mask)[0]\n",
    "\n",
    "print(f\"Found {len(good_positions)} good predictions\")\n",
    "\n",
    "# Get one example (use position, not index)\n",
    "pos = good_positions[0]\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GOOD DEMO EXAMPLE:\")\n",
    "print(\"=\"*60)\n",
    "print(X_test.iloc[pos])\n",
    "print(f\"\\nActual: {y_test.iloc[pos]:.4f}\")\n",
    "print(f\"Predicted: {lgb_pred[pos]:.4f}\")\n",
    "print(f\"Error: {errors[pos]:.2f}%\")\n",
    "\n",
    "# Get the original data to see what crop/state/season it is\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ORIGINAL VALUES (before encoding):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# You'll need to reverse the encoding to see the actual values\n",
    "# Let's get a few good examples\n",
    "print(\"\\nTop 5 best predictions:\")\n",
    "best_positions = good_positions[np.argsort(errors[good_mask])[:5]]\n",
    "for i, pos in enumerate(best_positions):\n",
    "    print(f\"\\n{i+1}. Actual: {y_test.iloc[pos]:.4f}, Predicted: {lgb_pred[pos]:.4f}, Error: {errors[pos]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea43294d-301c-438a-84c8-0cc8d6e87ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SAVING MODEL AND ENCODINGS\n",
      "============================================================\n",
      "\n",
      "âœ… Saved:\n",
      "   - best_model.pkl\n",
      "   - encoders.pkl\n",
      "   - feature_order.pkl\n",
      "   - target_encodings.pkl (NEW!)\n",
      "\n",
      "Features: 23\n",
      "RÂ²: 0.8823\n",
      "\n",
      "============================================================\n",
      "âœ… TRAINING COMPLETE!\n",
      "============================================================\n",
      "\n",
      "Next: Update backend/utils/preprocess.py with target encoding logic\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING MODEL AND ENCODINGS\")\n",
    "print(\"=\"*60)\n",
    "joblib.dump(best_lgb, '../backend/ml/best_model_final.pkl')\n",
    "joblib.dump(encoders, '../backend/ml/encoders_final.pkl')\n",
    "joblib.dump(feature_order, '../backend/ml/feature_order_final.pkl')\n",
    "joblib.dump(target_encodings, '../backend/ml/target_encodings_final.pkl')\n",
    "print(f\"\\nâœ… Saved:\")\n",
    "print(f\"   - best_model.pkl\")\n",
    "print(f\"   - encoders.pkl\")\n",
    "print(f\"   - feature_order.pkl\")\n",
    "print(f\"   - target_encodings.pkl (NEW!)\")\n",
    "print(f\"\\nFeatures: {len(feature_order)}\")\n",
    "print(f\"RÂ²: {lgb_r2:.4f}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… TRAINING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nNext: Update backend/utils/preprocess.py with target encoding logic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21f800a-23a1-4ee1-8239-551c8b787fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
